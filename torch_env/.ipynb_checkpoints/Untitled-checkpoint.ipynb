{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import *\n",
    "tensor = torch.randn(1, 1, 15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(Module):\n",
    "    def __init__(self, Conv2d_channels=1, kernel_size=3, batch_length=15):\n",
    "        super(Network, self).__init__()\n",
    "        self.module = Sequential(Conv2d(Conv2d_channels, Conv2d_channels, kernel_size, padding=1),  # -> 1x1x15x15\n",
    "                                 MaxPool2d(kernel_size),  # -> 1x1x5x5\n",
    "                                 Linear(batch_length // kernel_size, Conv2d_channels),\n",
    "                                 Softplus(),\n",
    "                                 )\n",
    "\n",
    "    @staticmethod\n",
    "    def _2dimSqueezeTo4d(tensor: torch.Tensor, size) -> torch.Tensor:\n",
    "        return tensor.reshape([1, 1, *size])\n",
    "\n",
    "    def forward(self, tensor) -> torch.Tensor:\n",
    "        return self.module(tensor)\n",
    "net = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.5480],\n",
       "           [0.6713],\n",
       "           [0.5807],\n",
       "           [0.7978],\n",
       "           [0.7653]]]], grad_fn=<SoftplusBackward0>),\n",
       " tensor([[[[-0.3494,  0.8007,  0.5914, -0.8217,  1.0912, -0.1729, -1.1151,\n",
       "            -0.5736,  0.0286, -0.3966,  0.9172, -0.1344, -0.0451, -1.0895,\n",
       "             2.8599],\n",
       "           [-0.1563, -1.7958, -1.2236, -1.2744, -1.1783, -0.2082, -0.7413,\n",
       "            -1.8617, -0.1435,  0.7175, -0.6122, -0.6216,  1.0973,  0.0248,\n",
       "            -0.5090],\n",
       "           [-0.1655,  0.8608,  0.2681, -0.1716,  0.4174, -0.5425,  0.9882,\n",
       "             0.1730, -0.4059,  1.3948,  0.2543,  0.3131,  0.4573,  0.8487,\n",
       "             0.4510],\n",
       "           [-0.2437, -0.9864, -0.3905,  1.1724, -0.2594, -0.1414, -1.8012,\n",
       "            -0.5207, -0.5473,  0.7739,  0.4768, -0.1837,  0.2273,  0.1766,\n",
       "             1.2610],\n",
       "           [-0.7450, -0.0343, -0.1140, -0.4791, -1.2068,  1.6774, -0.6082,\n",
       "             1.2296,  0.2008,  0.3436, -1.6597,  0.3277, -0.0964, -0.1552,\n",
       "            -1.8716],\n",
       "           [ 1.5673,  0.2743,  0.9506, -0.1964, -0.1250, -1.6262,  0.5197,\n",
       "            -1.3746, -0.2551, -0.3999, -0.5263,  0.3489,  0.8298,  0.2846,\n",
       "            -0.2649],\n",
       "           [-1.5418,  1.5000, -0.6400, -0.4211,  0.1159, -0.5838,  0.4585,\n",
       "            -0.7437, -0.7255, -0.3460,  0.4520,  0.2235,  0.7702,  1.4919,\n",
       "             1.4107],\n",
       "           [-0.5946, -0.5317, -0.8671, -0.2631,  0.6688,  0.9573, -0.5511,\n",
       "             0.3992,  1.0995,  0.9388, -0.7186,  0.9974, -1.0204,  2.1343,\n",
       "            -0.1931],\n",
       "           [-1.4232, -0.0952,  0.9962,  1.5002, -1.4241,  1.5731,  0.4182,\n",
       "            -1.6822,  0.7019,  0.0740,  0.3774,  0.0327,  1.5024, -1.1752,\n",
       "             0.9052],\n",
       "           [ 0.0085, -1.5606, -0.1785, -0.9067, -1.4352,  0.0994, -0.5953,\n",
       "             1.3316,  1.1690, -2.0745, -1.6189,  0.3127, -0.3680, -0.4951,\n",
       "             1.1380],\n",
       "           [-0.7767, -0.2618, -1.8789,  0.5371,  1.4696, -1.4406,  0.5206,\n",
       "             0.4556,  0.5261, -0.7090, -0.4528, -1.5078, -0.6426,  0.8290,\n",
       "            -0.3988],\n",
       "           [-0.0315,  0.4171, -0.7625, -0.8857, -0.4298,  0.9446, -1.4372,\n",
       "             1.2308, -0.9589,  0.1844, -0.0848, -0.8659, -1.1756,  0.4668,\n",
       "             1.8335],\n",
       "           [ 0.8768, -0.6038, -1.4174, -0.2640,  0.7690, -1.2770,  1.3419,\n",
       "            -0.8887,  0.0654, -0.7679, -0.7885,  0.9124, -1.7713,  1.0656,\n",
       "            -1.7784],\n",
       "           [-0.8175,  0.0622,  0.6647,  1.2965, -0.4773,  1.2751,  1.6667,\n",
       "            -1.4213,  1.9859,  1.3113, -0.7762, -1.6527, -0.4062,  0.8754,\n",
       "            -0.9332],\n",
       "           [-0.2846,  0.6907, -0.8199, -0.4592,  0.7485,  0.8521,  0.7756,\n",
       "             0.7379,  0.4935, -0.2489, -1.7660, -0.1731,  2.4637, -1.2166,\n",
       "            -0.6033]]]]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
